from typing import Any, Text, Dict, List
from rasa_sdk import Action, Tracker
from rasa_sdk.executor import CollectingDispatcher


import re
from typing import Any, Text, Dict, List
from rasa_sdk import Action, Tracker
from rasa_sdk.executor import CollectingDispatcher


class ActionReadLawSection(Action):
    def name(self) -> Text:
        return "action_read_law_section"

    def run(self, dispatcher: CollectingDispatcher,
            tracker: Tracker,
            domain: Dict[Text, Any]) -> List[Dict[Text, Any]]:

        user_message = tracker.latest_message.get('text', '')

        print(f"\n{'=' * 60}")
        print(f"[NEW CODE] User message: '{user_message}'")
        print(f"{'=' * 60}")

        # T√¨m t·∫•t c·∫£ c√°c s·ªë
        numbers = re.findall(r'\d+', user_message)

        if not numbers:
            print("[NEW CODE] Kh√¥ng t√¨m th·∫•y s·ªë!")
            dispatcher.utter_message(text="B·∫°n vui l√≤ng cho bi·∫øt r√µ s·ªë ƒëi·ªÅu b·∫°n mu·ªën tra c·ª©u nh√©.")
            return []

        dieu = numbers[0]
        print(f"[NEW CODE] ƒêi·ªÅu s·ªë t√¨m th·∫•y: {dieu}")

        # Chu·∫©n h√≥a message - b·ªè d·∫•u, lowercase
        def normalize_text(text):
            """Chu·∫©n h√≥a vƒÉn b·∫£n: b·ªè d·∫•u ti·∫øng Vi·ªát, lowercase"""
            replacements = {
                '√°': 'a', '√†': 'a', '·∫£': 'a', '√£': 'a', '·∫°': 'a',
                'ƒÉ': 'a', '·∫Ø': 'a', '·∫±': 'a', '·∫≥': 'a', '·∫µ': 'a', '·∫∑': 'a',
                '√¢': 'a', '·∫•': 'a', '·∫ß': 'a', '·∫©': 'a', '·∫´': 'a', '·∫≠': 'a',
                'ƒë': 'd',
                '√©': 'e', '√®': 'e', '·∫ª': 'e', '·∫Ω': 'e', '·∫π': 'e',
                '√™': 'e', '·∫ø': 'e', '·ªÅ': 'e', '·ªÉ': 'e', '·ªÖ': 'e', '·ªá': 'e',
                '√≠': 'i', '√¨': 'i', '·ªâ': 'i', 'ƒ©': 'i', '·ªã': 'i',
                '√≥': 'o', '√≤': 'o', '·ªè': 'o', '√µ': 'o', '·ªç': 'o',
                '√¥': 'o', '·ªë': 'o', '·ªì': 'o', '·ªï': 'o', '·ªó': 'o', '·ªô': 'o',
                '∆°': 'o', '·ªõ': 'o', '·ªù': 'o', '·ªü': 'o', '·ª°': 'o', '·ª£': 'o',
                '√∫': 'u', '√π': 'u', '·ªß': 'u', '≈©': 'u', '·ª•': 'u',
                '∆∞': 'u', '·ª©': 'u', '·ª´': 'u', '·ª≠': 'u', '·ªØ': 'u', '·ª±': 'u',
                '√Ω': 'y', '·ª≥': 'y', '·ª∑': 'y', '·ªπ': 'y', '·ªµ': 'y',
            }
            text = text.lower()
            for vn, en in replacements.items():
                text = text.replace(vn, en)
            return text

        user_normalized = normalize_text(user_message)
        print(f"[NEW CODE] Normalized: '{user_normalized}'")

        # Nh·∫≠n d·∫°ng vƒÉn b·∫£n v·ªõi regex SI√äU LINH HO·∫†T

        # ===== NGH·ªä ƒê·ªäNH =====
        # Match: ngh·ªã ƒë·ªãnh, nghi dinh, nƒë, nd, ngh dinh, nghi d·ªãnh, ngh·ªã ƒëinh...
        nghi_dinh_patterns = [
            r'ngh?[ie]?\s*d[ie]?nh',  # nghi dinh, ngh dinh, nghidinh
            r'n[dƒë]\s*\d+',  # nd105, nƒë 105
            r'n[dƒë][-\s]?cp',  # nd-cp, nƒë cp
        ]

        is_nghi_dinh = any(re.search(pattern, user_normalized) for pattern in nghi_dinh_patterns)

        # ===== TH√îNG T∆Ø =====
        # Match: th√¥ng t∆∞, thong tu, tt, th√¥ng tu, thong t∆∞...
        thong_tu_patterns = [
            r'th[o√¥]?ng?\s*t[u∆∞]',  # thong tu, th√¥ng t∆∞, thng tu
            r'tt\s*\d+',  # tt38, tt 38
            r'tt[-\s]?bca',  # tt-bca, tt bca
        ]

        is_thong_tu = any(re.search(pattern, user_normalized) for pattern in thong_tu_patterns)

        # ===== LU·∫¨T =====
        # Match: lu·∫≠t, luat, l, pccc, ph√≤ng ch√°y, phong chay...
        luat_patterns = [
            r'lu[a·∫≠]?t',  # lu·∫≠t, luat, lu√¢t, lut
            r'\bl\b',  # " l " (ch·ªØ l ri√™ng l·∫ª)
            r'pccc',
            r'ph[o√≤]?ng\s*ch[a√°]y',  # ph√≤ng ch√°y, phong chay
        ]

        is_luat = any(re.search(pattern, user_normalized) for pattern in luat_patterns)

        # Quy·∫øt ƒë·ªãnh vƒÉn b·∫£n (∆∞u ti√™n: Ngh·ªã ƒë·ªãnh > Th√¥ng t∆∞ > Lu·∫≠t)
        if is_nghi_dinh:
            file_path = "data/files/nghi_dinh_105_2025.txt"
            doc_name = "Ngh·ªã ƒë·ªãnh 105/2025/Nƒê-CP"
        elif is_thong_tu:
            file_path = "data/files/thong_tu_38_2025.txt"
            doc_name = "Th√¥ng t∆∞ 38/2025/TT-BCA"
        else:
            # M·∫∑c ƒë·ªãnh: Lu·∫≠t PCCC (k·ªÉ c·∫£ khi kh√¥ng c√≥ t·ª´ kh√≥a)
            file_path = "data/files/luat_pccc_2024.txt"
            doc_name = "Lu·∫≠t Ph√≤ng ch√°y, ch·ªØa ch√°y v√† C·ª©u n·∫°n, c·ª©u h·ªô 2024"

        print(f"[NEW CODE] Document: {doc_name}")

        # Pattern t√¨m ƒêi·ªÅu trong file
        pattern = fr"ƒêi·ªÅu\s+{dieu}\..*?(?=ƒêi·ªÅu\s+\d+\.|$)"

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                text = f.read()

            print(f"[NEW CODE] ƒê·ªçc file th√†nh c√¥ng, ƒë·ªô d√†i: {len(text)} k√Ω t·ª±")

            match = re.search(pattern, text, re.DOTALL)

            if match:
                section = match.group(0).strip()
                print(f"[NEW CODE] T√¨m th·∫•y! ƒê·ªô d√†i: {len(section)} k√Ω t·ª±")

                dispatcher.utter_message(text=f"üìÑ {doc_name}\n\n{section}")
            else:
                print(f"[NEW CODE] KH√îNG t√¨m th·∫•y ƒêi·ªÅu {dieu}")
                dispatcher.utter_message(text=f"Kh√¥ng t√¨m th·∫•y ƒêi·ªÅu {dieu} trong {doc_name}.")

        except FileNotFoundError:
            print(f"[NEW CODE] L·ªñI: Kh√¥ng t√¨m th·∫•y file {file_path}")
            dispatcher.utter_message(text="‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file lu·∫≠t")
        except Exception as e:
            print(f"[NEW CODE] L·ªñI: {e}")
            dispatcher.utter_message(text=f"‚ùå L·ªói: {e}")

        return []


